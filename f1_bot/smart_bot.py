import logging
from telegram import Update, ReplyKeyboardMarkup, KeyboardButton, ReplyKeyboardRemove
from telegram.ext import Updater, CommandHandler, MessageHandler, filters, ConversationHandler, CallbackContext
from bs4 import BeautifulSoup
import json
import os
from datetime import datetime
from typing import Dict, List
import random

# –ó–∞—â–∏—â–µ–Ω–Ω—ã–π –∏–º–ø–æ—Ä—Ç –ò–ò –±–∏–±–ª–∏–æ—Ç–µ–∫
try:
    from sentence_transformers import SentenceTransformer, util
    import torch
    AI_AVAILABLE = True
except ImportError:
    AI_AVAILABLE = False
    print("AI libraries not available - running in simple mode")

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO)
logger = logging.getLogger(__name__)

# –¢–æ–∫–µ–Ω –±–æ—Ç–∞
TOKEN = "8464916111:AAGGy0HS7GrbwITL_hb6SePhlX2zkJIi4Ik"

# –°–æ—Å—Ç–æ—è–Ω–∏—è —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
LANGUAGE, NAME, MAIN_MENU, AI_STYLE, QUESTION, IMAGE_GEN = range(6)

# –î–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
user_data = {}

# –î–æ—Å—Ç—É–ø–Ω—ã–µ —è–∑—ã–∫–∏
LANGUAGES = {
    "üá∑üá∫ –†—É—Å—Å–∫–∏–π": "ru",
    "üá∫üá∏ English": "en", 
    "üá™üá∏ Espa√±ol": "es",
    "üá´üá∑ Fran√ßais": "fr",
    "üá©üá™ Deutsch": "de"
}

# –°—Ç–∏–ª–∏ –ò–ò –¥–ª—è –æ—Ç–≤–µ—Ç–æ–≤
AI_STYLES = {
    "ü§ñ –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π": "universal",
    "üíª IT-–°–ø–µ—Ü–∏–∞–ª–∏—Å—Ç": "it",
    "üé® –¢–≤–æ—Ä—á–µ—Å–∫–∏–π": "creative",
    "üìö –ù–∞—É—á–Ω—ã–π": "scientific", 
    "üí∞ –§–∏–Ω–∞–Ω—Å–æ–≤—ã–π": "financial"
}

# –¢–µ–∫—Å—Ç—ã –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —è–∑—ã–∫–∞—Ö
TEXTS = {
    "ru": {
        "welcome": "üåç –í—ã–±–µ—Ä–∏—Ç–µ —è–∑—ã–∫:",
        "name_ask": "–ö–∞–∫ –≤–∞—Å –∑–æ–≤—É—Ç?",
        "greeting": "–ü—Ä–∏–≤–µ—Ç, {name}! –†–∞–¥ –∑–Ω–∞–∫–æ–º—Å—Ç–≤—É!",
        "main_menu": "–ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é:",
        "ai_style": "–í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç–∏–ª—å –æ—Ç–≤–µ—Ç–∞:",
        "ask_question": "–ó–∞–¥–∞–π—Ç–µ –≤–∞—à –≤–æ–ø—Ä–æ—Å:",
        "searching": "üîç –ò—â—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é...",
        "settings": "‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏",
        "info": "‚ÑπÔ∏è –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è",
        "generate_image": "üé® –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ",
        "ask_image": "–û–ø–∏—à–∏—Ç–µ —á—Ç–æ –≤—ã —Ö–æ—Ç–∏—Ç–µ —É–≤–∏–¥–µ—Ç—å –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏:",
        "image_created": "üñºÔ∏è –í–∞—à–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≥–æ—Ç–æ–≤–æ!",
        "error": "‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞.",
        "thanks": "–°–ø–∞—Å–∏–±–æ –∑–∞ –≤–æ–ø—Ä–æ—Å! üòä",
        "smart_response": "üß† –£–º–Ω—ã–π –æ—Ç–≤–µ—Ç",
        "deep_search": "üîç –ì–ª—É–±–æ–∫–∏–π –ø–æ–∏—Å–∫"
    },
    "en": {
        "welcome": "üåç Choose language:",
        "name_ask": "What is your name?",
        "greeting": "Hello, {name}! Nice to meet you!",
        "main_menu": "Main menu:",
        "ai_style": "Choose response style:",
        "ask_question": "Ask your question:",
        "searching": "üîç Searching for information...",
        "settings": "‚öôÔ∏è Settings",
        "info": "‚ÑπÔ∏è Information", 
        "generate_image": "üé® Generate image",
        "ask_image": "Describe what you want to see in the image:",
        "image_created": "üñºÔ∏è Your image is ready!",
        "error": "‚ùå An error occurred. Please try again.",
        "thanks": "Thanks for your question! üòä",
        "smart_response": "üß† Smart response",
        "deep_search": "üîç Deep search"
    }
}

class SmartAssistant:
    def __init__(self):
        self.model = None
        self.knowledge = []
        
        if AI_AVAILABLE:
            try:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –ª–µ–≥–∫—É—é –º–æ–¥–µ–ª—å
                self.model = SentenceTransformer('paraphrase-albert-small-v2')
                logger.info("AI model loaded successfully")
            except Exception as e:
                logger.error(f"AI model loading error: {e}")
                self.model = None
        else:
            logger.info("AI mode disabled - running without neural networks")
        
    def add_knowledge(self, text: str, source: str = ""):
        """–î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π"""
        if len(text) > 50:
            self.knowledge.append({
                "text": text,
                "source": source,
                "timestamp": datetime.now().isoformat()
            })
    
    def find_similar(self, question: str, top_k: int = 3):
        """–ù–∞—Ö–æ–¥–∏–º –ø–æ—Ö–æ–∂—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π"""
        if not self.knowledge or not self.model:
            return []
            
        try:
            question_embedding = self.model.encode(question, convert_to_tensor=True)
            knowledge_texts = [k["text"] for k in self.knowledge]
            knowledge_embeddings = self.model.encode(knowledge_texts, convert_to_tensor=True)
            
            similarities = util.pytorch_cos_sim(question_embedding, knowledge_embeddings)[0]
            
            results = []
            for i in torch.topk(similarities, min(top_k, len(similarities))).indices:
                results.append(self.knowledge[i.item()])
            
            return results
        except Exception as e:
            logger.error(f"Similarity search error: {e}")
            return []

# –°–æ–∑–¥–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –ò–ò
assistant = SmartAssistant()

def google_search(query, lang="ru"):
    """–£–º–Ω—ã–π –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–∏—Å–∫"""
    try:
        query_lower = query.lower()
        
        # –ü—Ä—è–º—ã–µ —Å—Å—ã–ª–∫–∏ –¥–ª—è –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        direct_sources = []
        
        if any(word in query_lower for word in ['–ø—É—Ç–∏–Ω', '–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç', '–∫—Ä–µ–º–ª—å', '–ø—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–æ']):
            direct_sources = [
                "https://www.rbc.ru/politics/",
                "https://ria.ru/politics/",
                "https://tass.ru/politika"
            ]
        elif any(word in query_lower for word in ['–Ω–æ–≤–æ—Å—Ç–∏', '—Å–æ–±—ã—Ç–∏—è', '–ø—Ä–æ–∏—Å—à–µ—Å—Ç–≤–∏—è']):
            direct_sources = [
                "https://www.rbc.ru/",
                "https://ria.ru/",
                "https://lenta.ru/"
            ]
        elif any(word in query_lower for word in ['—Å–ø–æ—Ä—Ç', '—Ñ—É—Ç–±–æ–ª', '—Ö–æ–∫–∫–µ–π', '–±–∞—Å–∫–µ—Ç–±–æ–ª']):
            direct_sources = [
                "https://www.championat.com/",
                "https://sport.rbc.ru/",
                "https://www.sports.ru/"
            ]
        elif any(word in query_lower for word in ['—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏', '–≥–∞–¥–∂–µ—Ç—ã', 'it', '–∫–æ–º–ø—å—é—Ç–µ—Ä']):
            direct_sources = [
                "https://habr.com/ru/news/",
                "https://www.ixbt.com/news/",
                "https://vc.ru/tech"
            ]
        
        # –ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ —Ä–∞–∑–Ω—ã–µ –ø–æ–∏—Å–∫–æ–≤–∏–∫–∏
        search_results = []
        search_engines = [
            f"https://www.bing.com/search?q={query}&cc=RU",
            f"https://duckduckgo.com/html/?q={query}",
            f"https://html.duckduckgo.com/html/?q={query}"
        ]
        
        for search_url in search_engines:
            if len(search_results) >= 2:
                break
                
            try:
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                }
                
                response = requests.get(search_url, headers=headers, timeout=8)
                response.encoding = 'utf-8'
                
                if response.status_code == 200:
                    soup = BeautifulSoup(response.text, 'html.parser')
                    
                    for link in soup.find_all('a', href=True):
                        href = link['href']
                        if (href.startswith('http') and 
                            not any(domain in href for domain in ['bing.com', 'duckduckgo.com', 'google.com', 'yandex.ru']) and
                            len(href) < 120 and
                            href not in search_results):
                            
                            search_results.append(href)
                            if len(search_results) >= 3:
                                break
            except:
                continue
        
        # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        all_results = direct_sources + search_results
        unique_results = []
        seen = set()
        for result in all_results:
            if result not in seen:
                seen.add(result)
                unique_results.append(result)
            if len(unique_results) >= 3:
                break
        
        return unique_results if unique_results else [
            "https://www.rbc.ru/",
            "https://ria.ru/",
            "https://lenta.ru/"
        ]
        
    except Exception as e:
        logger.error(f"Search error: {e}")
        return [
            "https://www.rbc.ru/",
            "https://ria.ru/", 
            "https://lenta.ru/"
        ]

def extract_info_from_page(url):
    """–£–º–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ —Å –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –ø–æ–¥—Ö–æ–¥–æ–º"""
    try:
        # –ë—ã—Å—Ç—Ä–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–ª—è –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö —Å–∞–π—Ç–æ–≤
        site_info = {
            'rbc.ru': '–†–ë–ö - –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ–ª–∏—Ç–∏–∫–∏ –∏ —ç–∫–æ–Ω–æ–º–∏–∫–∏',
            'ria.ru': '–†–ò–ê –ù–æ–≤–æ—Å—Ç–∏ - –ø–æ—Å–ª–µ–¥–Ω–∏–µ –Ω–æ–≤–æ—Å—Ç–∏ –†–æ—Å—Å–∏–∏ –∏ –º–∏—Ä–∞', 
            'tass.ru': '–¢–ê–°–° - –Ω–æ–≤–æ—Å—Ç–∏ –ø–æ–ª–∏—Ç–∏–∫–∏ –∏ –∫—É–ª—å—Ç—É—Ä—ã',
            'lenta.ru': '–õ–µ–Ω—Ç–∞.—Ä—É - —Å–≤–µ–∂–∏–µ –Ω–æ–≤–æ—Å—Ç–∏ –∏ —Å–æ–±—ã—Ç–∏—è',
            'championat.com': '–ß–µ–º–ø–∏–æ–Ω–∞—Ç - –Ω–æ–≤–æ—Å—Ç–∏ —Å–ø–æ—Ä—Ç–∞',
            'sports.ru': 'Sports.ru - —Å–ø–æ—Ä—Ç–∏–≤–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏',
            'habr.com': 'Habr - –Ω–æ–≤–æ—Å—Ç–∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π –∏ IT',
            'ixbt.com': 'IXBT - –Ω–æ–≤–æ—Å—Ç–∏ –≤—ã—Å–æ–∫–∏—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π',
            'vc.ru': 'VC.ru - –±–∏–∑–Ω–µ—Å –∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏'
        }
        
        for domain, info in site_info.items():
            if domain in url:
                assistant.add_knowledge(info, url)
                return info
        
        # –î–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è –¥—Ä—É–≥–∏—Ö —Å–∞–π—Ç–æ–≤
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
        }
        
        response = requests.get(url, headers=headers, timeout=10)
        response.encoding = 'utf-8'
        
        if response.status_code == 200:
            soup = BeautifulSoup(response.text, 'html.parser')
            
            for element in soup(['script', 'style', 'nav', 'footer', 'header', 'aside', 'form']):
                element.decompose()
            
            # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 1: –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            title = soup.find('title')
            title_text = title.get_text().strip() if title else ""
            
            # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 2: –û—Å–Ω–æ–≤–Ω–æ–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ h1
            h1 = soup.find('h1')
            h1_text = h1.get_text().strip() if h1 else ""
            
            # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 3: –ú–µ—Ç–∞-–æ–ø–∏—Å–∞–Ω–∏–µ
            meta_desc = soup.find('meta', attrs={'name': 'description'})
            meta_text = meta_desc['content'].strip() if meta_desc and meta_desc.get('content') else ""
            
            # –°—Ç—Ä–∞—Ç–µ–≥–∏—è 4: –ü–µ—Ä–≤—ã–µ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã
            paragraphs = []
            for p in soup.find_all('p'):
                text = p.get_text().strip()
                if (len(text) > 40 and 
                    len(text) < 300 and
                    not any(word in text.lower() for word in ['—Ä–µ–∫–ª–∞–º–∞', 'cookie', '¬©', 'copyright', '–ø–æ–ª–∏—Ç–∏–∫–∞'])):
                    paragraphs.append(text)
                    if len(paragraphs) >= 2:
                        break
            
            # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à–∏–π –≤–∞—Ä–∏–∞–Ω—Ç
            best_text = ""
            candidates = [h1_text, meta_text, title_text] + paragraphs
            
            for candidate in candidates:
                if (candidate and 
                    len(candidate) > 20 and 
                    len(candidate) < 250 and
                    not candidate.startswith('http')):
                    best_text = candidate
                    break
            
            if best_text:
                clean_text = ' '.join(best_text.split())
                if len(clean_text) > 150:
                    clean_text = clean_text[:150] + "..."
                
                assistant.add_knowledge(clean_text, url)
                return clean_text
            
            return "–ò–Ω—Ç–µ—Ä–µ—Å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É! –†–µ–∫–æ–º–µ–Ω–¥—É—é –æ–∑–Ω–∞–∫–æ–º–∏—Ç—å—Å—è —Å –∏—Å—Ç–æ—á–Ω–∏–∫–æ–º."
            
        return "–ê–∫—Ç—É–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–∞–π–¥–µ–Ω—ã! üìñ"
        
    except Exception as e:
        logger.error(f"Page extract error: {e}")
        return "–ù–∞—à–µ–ª —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é! üîç"

def generate_smart_response(question: str, context: str = "", lang: str = "ru") -> str:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–º–Ω—ã–π –æ—Ç–≤–µ—Ç —Å –ø–æ–º–æ—â—å—é –ò–ò"""
    try:
        # –ü—Ä–æ—Å—Ç—ã–µ –ø—Ä–∞–≤–∏–ª–∞ –¥–ª—è —á–∞—Å—Ç—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤
        simple_answers = {
            "ru": {
                "–ø—Ä–∏–≤–µ—Ç": "–ü—Ä–∏–≤–µ—Ç! üòä –ö–∞–∫ —è –º–æ–≥—É –ø–æ–º–æ—á—å?",
                "–∫–∞–∫ –¥–µ–ª–∞": "–£ –º–µ–Ω—è –≤—Å–µ –æ—Ç–ª–∏—á–Ω–æ! –ì–æ—Ç–æ–≤ –ø–æ–º–æ—á—å —Å –ª—é–±—ã–º –≤–æ–ø—Ä–æ—Å–æ–º!",
                "—Å–ø–∞—Å–∏–±–æ": "–í—Å–µ–≥–¥–∞ –ø–æ–∂–∞–ª—É–π—Å—Ç–∞! –û–±—Ä–∞—â–∞–π—Ç–µ—Å—å –µ—â–µ! üôè",
                "—á—Ç–æ —Ç—ã —É–º–µ–µ—à—å": "–Ø –º–æ–≥—É –∏—Å–∫–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –∏ –ø–æ–º–æ–≥–∞—Ç—å —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ –∑–∞–¥–∞—á–∞–º–∏!",
                "–∫—Ç–æ —Ç—ã": "–Ø —É–º–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ —Å –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–º –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–æ–º! ü§ñ",
                "time": f"–°–µ–π—á–∞—Å {datetime.now().strftime('%H:%M')} ‚è∞",
                "date": f"–°–µ–≥–æ–¥–Ω—è {datetime.now().strftime('%d.%m.%Y')} üìÖ",
            },
            "en": {
                "hello": "Hi! üòä How can I help you?",
                "how are you": "I'm great! Ready to help with any question!",
                "thank you": "You're welcome! Feel free to ask more! üôè",
                "what can you do": "I can search information, answer questions and help with various tasks!",
                "who are you": "I'm a smart AI assistant! ü§ñ",
                "time": f"Current time: {datetime.now().strftime('%H:%M')} ‚è∞",
                "date": f"Today is {datetime.now().strftime('%Y-%m-%d')} üìÖ",
            }
        }
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–æ—Å—Ç—ã–µ –≤–æ–ø—Ä–æ—Å—ã
        question_lower = question.lower()
        lang_dict = simple_answers.get(lang, simple_answers["ru"])
        
        for key, answer in lang_dict.items():
            if key in question_lower:
                return answer
        
        # –ò—â–µ–º –ø–æ—Ö–æ–∂—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –ò–ò –¥–æ—Å—Ç—É–ø–µ–Ω)
        similar_info = []
        if assistant.model:
            similar_info = assistant.find_similar(question)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –æ—Ç–≤–µ—Ç–∞
        context_text = ""
        if similar_info:
            context_text = "–ù–∞ –æ—Å–Ω–æ–≤–µ –º–æ–∏—Ö –∑–Ω–∞–Ω–∏–π:\n" + "\n".join([info["text"] for info in similar_info[:2]])
        
        if context:
            context_text += f"\n\n–ò–∑ –Ω–∞–π–¥–µ–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏:\n{context}"
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–º–Ω—ã–π –æ—Ç–≤–µ—Ç
        if context_text:
            return f"{context_text[:600]}...\n\n–ú–æ–≥—É —É—Ç–æ—á–Ω–∏—Ç—å –¥–µ—Ç–∞–ª–∏ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ! üîç"
        
        # –£–º–Ω—ã–π –æ—Ç–≤–µ—Ç –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        smart_responses = {
            "ru": [
                f"–ü–æ –≤–æ–ø—Ä–æ—Å—É '{question}' —è –Ω–∞—à–µ–ª –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ! üìä",
                f"–ê–Ω–∞–ª–∏–∑–∏—Ä—É—é '{question}'... –ï—Å—Ç—å –∞–∫—Ç—É–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è! üîç",
                f"–û—Ç–ª–∏—á–Ω—ã–π –≤–æ–ø—Ä–æ—Å! –ü–æ —Ç–µ–º–µ '{question}' –µ—Å—Ç—å –º–Ω–æ–≥–æ —Å–≤–µ–∂–∏—Ö –¥–∞–Ω–Ω—ã—Ö. üí°",
                f"–ò–∑—É—á–∞—é '{question}'... –ù–∞—à–µ–ª –∫–æ–µ-—á—Ç–æ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ–µ! üéØ",
                f"–ü–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É '{question}' - –µ—Å—Ç—å –ø–æ–ª–µ–∑–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è! üìö"
            ],
            "en": [
                f"Regarding '{question}' I found interesting data! üìä",
                f"Analyzing '{question}'... There is relevant information! üîç",
                f"Great question! There is a lot of fresh data on '{question}'. üí°",
                f"Researching '{question}'... Found something interesting! üéØ",
                f"For your query '{question}' - there is useful information! üìö"
            ]
        }
        
        return random.choice(smart_responses.get(lang, smart_responses["ru"]))
        
    except Exception as e:
        logger.error(f"Response generation error: {e}")
        return "–ò–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π –≤–æ–ø—Ä–æ—Å! –î–∞–≤–∞–π—Ç–µ –æ–±—Å—É–¥–∏–º –µ–≥–æ –ø–æ–¥—Ä–æ–±–Ω–µ–µ. üí≠"

# ========== –û–°–¢–ê–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò –ë–ï–ó –ò–ó–ú–ï–ù–ï–ù–ò–ô ==========

async def start(update, context):
    """–ù–∞—á–∞–ª–æ —Ä–∞–±–æ—Ç—ã - –≤—ã–±–æ—Ä —è–∑—ã–∫–∞"""
    keyboard = [[KeyboardButton(lang)] for lang in LANGUAGES.keys()]
    reply_markup = ReplyKeyboardMarkup(keyboard, one_time_keyboard=True, resize_keyboard=True)
    
    await update.message.reply_text("üåç Choose your language / –í—ã–±–µ—Ä–∏—Ç–µ —è–∑—ã–∫:", reply_markup=reply_markup)
    return LANGUAGE

async def language_handler(update, context):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤—ã–±–æ—Ä–∞ —è–∑—ã–∫–∞"""
    user_lang_name = update.message.text
    user_id = update.message.from_user.id
    
    if user_lang_name in LANGUAGES:
        lang_code = LANGUAGES[user_lang_name]
        user_data[user_id] = {"lang": lang_code}
        
        texts = TEXTS.get(lang_code, TEXTS["ru"])
        await update.message.reply_text(texts["name_ask"], reply_markup=ReplyKeyboardRemove())
        return NAME
    else:
        await update.message.reply_text("Please choose from the list / –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ –∏–∑ —Å–ø–∏—Å–∫–∞")
        return LANGUAGE

async def name_handler(update, context):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∏–º–µ–Ω–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    user_id = update.message.from_user.id
    name = update.message.text
    lang_code = user_data[user_id]["lang"]
    user_data[user_id]["name"] = name
    
    texts = TEXTS.get(lang_code, TEXTS["ru"])
    
    # –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é
    keyboard = [
        [KeyboardButton(texts["ask_question"])],
        [KeyboardButton(texts["generate_image"]), KeyboardButton(texts["settings"])],
        [KeyboardButton(texts["info"])]
    ]
    reply_markup = ReplyKeyboardMarkup(keyboard, resize_keyboard=True)
    
    await update.message.reply_text(texts["greeting"].format(name=name), reply_markup=reply_markup)
    return MAIN_MENU

async def main_menu_handler(update, context):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≥–ª–∞–≤–Ω–æ–≥–æ –º–µ–Ω—é"""
    user_id = update.message.from_user.id
    choice = update.message.text
    lang_code = user_data[user_id]["lang"]
    texts = TEXTS.get(lang_code, TEXTS["ru"])
    
    if choice == texts["ask_question"]:
        # –ö–ª–∞–≤–∏–∞—Ç—É—Ä–∞ –≤—ã–±–æ—Ä–∞ —Å—Ç–∏–ª—è –ò–ò
        keyboard = [[KeyboardButton(style)] for style in AI_STYLES.keys()]
        keyboard.append([KeyboardButton("‚¨ÖÔ∏è –ù–∞–∑–∞–¥")])
        reply_markup = ReplyKeyboardMarkup(keyboard, resize_keyboard=True)
        
        await update.message.reply_text(texts["ai_style"], reply_markup=reply_markup)
        return AI_STYLE
        
    elif choice == texts["generate_image"]:
        await update.message.reply_text(texts["ask_image"], reply_markup=ReplyKeyboardRemove())
        return IMAGE_GEN
        
    elif choice == texts["settings"]:
        await update.message.reply_text("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ...")
        return MAIN_MENU
        
    elif choice == texts["info"]:
        await update.message.reply_text("‚ÑπÔ∏è –≠—Ç–æ—Ç –±–æ—Ç –∏—Å–ø–æ–ª—å–∑—É–µ—Ç AI –¥–ª—è –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
        return MAIN_MENU
    
    return MAIN_MENU

async def ai_style_handler(update, context):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤—ã–±–æ—Ä–∞ —Å—Ç–∏–ª—è –ò–ò"""
    user_id = update.message.from_user.id
    choice = update.message.text
    lang_code = user_data[user_id]["lang"]
    texts = TEXTS.get(lang_code, TEXTS["ru"])
    
    if choice == "‚¨ÖÔ∏è –ù–∞–∑–∞–¥":
        return await main_menu_handler(update, context)
    
    if choice in AI_STYLES:
        user_data[user_id]["ai_style"] = AI_STYLES[choice]
        await update.message.reply_text(texts["ask_question"], reply_markup=ReplyKeyboardRemove())
        return QUESTION
    
    await update.message.reply_text("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ —Å—Ç–∏–ª—å –∏–∑ —Å–ø–∏—Å–∫–∞")
    return AI_STYLE

async def question_handler(update, context):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≤–æ–ø—Ä–æ—Å–æ–≤ - –¢–ï–ü–ï–†–¨ –° –ò–ò!"""
    user_id = update.message.from_user.id
    question = update.message.text
    lang_code = user_data[user_id]["lang"]
    texts = TEXTS.get(lang_code, TEXTS["ru"])
    
    await update.message.reply_text(texts["searching"])
    
    try:
        # 1. –ò—â–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ
        search_results = google_search(question, lang_code)
        context_info = ""
        
        if search_results:
            # 2. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
            page_text = extract_info_from_page(search_results[0])
            if page_text:
                context_info = page_text
        
        # 3. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–º–Ω—ã–π –æ—Ç–≤–µ—Ç —Å –ò–ò
        response = generate_smart_response(question, context_info, lang_code)
        
        # 4. –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫ –µ—Å–ª–∏ –µ—Å—Ç—å
        if search_results and context_info:
            response += f"\n\nüîó –ò—Å—Ç–æ—á–Ω–∏–∫: {search_results[0]}"
        
        await update.message.reply_text(response)
        await update.message.reply_text(texts["thanks"])
            
    except Exception as e:
        logger.error(f"Error: {e}")
        await update.message.reply_text(texts["error"])
    
    return MAIN_MENU

async def image_generation_handler(update, context):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
    user_id = update.message.from_user.id
    prompt = update.message.text
    lang_code = user_data[user_id]["lang"]
    texts = TEXTS.get(lang_code, TEXTS["ru"])
    
    await update.message.reply_text("üé® –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è... (—Ñ—É–Ω–∫—Ü–∏—è –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ)")
    
    # –ó–¥–µ—Å—å –±—É–¥–µ—Ç —Ä–µ–∞–ª—å–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    await update.message.reply_text(texts["image_created"])
    await update.message.reply_text("–í –±—É–¥—É—â–µ–π –≤–µ—Ä—Å–∏–∏ –∑–¥–µ—Å—å –±—É–¥–µ—Ç –≤–∞—à–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ!")
    
    return MAIN_MENU

async def cancel(update, context):
    """–û—Ç–º–µ–Ω–∞ –æ–ø–µ—Ä–∞—Ü–∏–∏"""
    await update.message.reply_text("–û–ø–µ—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞", reply_markup=ReplyKeyboardRemove())
    return ConversationHandler.END

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    updater = Updater(TOKEN, use_context=True)
    dp = updater.dispatcher
    
    conv_handler = ConversationHandler(
    entry_points=[CommandHandler('start', start)],
    states={
        LANGUAGE: [MessageHandler(filters.TEXT & ~filters.COMMAND, language_handler)],
        NAME: [MessageHandler(filters.TEXT & ~filters.COMMAND, name_handler)],
        MAIN_MENU: [MessageHandler(filters.TEXT & ~filters.COMMAND, main_menu_handler)],
        AI_STYLE: [MessageHandler(filters.TEXT & ~filters.COMMAND, ai_style_handler)],
        QUESTION: [MessageHandler(filters.TEXT & ~filters.COMMAND, question_handler)],
        IMAGE_GEN: [MessageHandler(filters.TEXT & ~filters.COMMAND, image_generation_handler)],
    },
    fallbacks=[CommandHandler('cancel', cancel)]
)
    
    
    dp.add_handler(conv_handler)
    print("ü§ñ –£–º–Ω—ã–π –±–æ—Ç —Å –ò–ò –∑–∞–ø—É—â–µ–Ω!")
    updater.start_polling()
    updater.idle()

if __name__ == "__main__":
    main()